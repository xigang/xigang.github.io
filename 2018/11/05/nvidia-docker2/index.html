<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>Nvidia-Docker2在kubernetes上实践 | xigang's home</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">Nvidia-Docker2在kubernetes上实践</h1><a id="logo" href="/.">xigang's home</a><p class="description">Do it right or don't do it at all</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">Nvidia-Docker2在kubernetes上实践</h1><div class="post-meta">Nov 5, 2018<span> | </span><span class="category"><a href="/categories/云计算/">云计算</a></span></div><div class="post-content"><p>现在公司线上所有的k8s集群对GPU资源的使用都是<code>nvidia-docker 1.0</code>(历史遗留问题)。并且还专门写了篇文章记录是如何使用的<a href="https://xigang.github.io/2018/09/01/gpu/" target="_blank" rel="noopener">GPU Container on Kubernetes</a>。但是现在的kubernetes1.9推荐使用<code>device plugin</code>的方式来对接外部厂商的资源。这样所有的厂商的资源就不要kubernetes去特定的支持，而是各服务厂商只要按照<code>kubernetes</code>提供的<a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/" target="_blank" rel="noopener">device plugin</a>实现自己的一套就可以了。今天就针对<code>nvidia-docker2.0</code> 进行了下测试。在此做下记录。</p>
<h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><ul>
<li>CentOS Linux release 7.2.1511 (Core)</li>
<li>kuberntes: 1.9</li>
<li>GPU: nvidia-tesla-k80</li>
</ul>
<h2 id="Installation-version-2-0"><a href="#Installation-version-2-0" class="headerlink" title="Installation (version 2.0)"></a>Installation (version 2.0)</h2><p>直接参照官方的安装教程:<a href="https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0">Installation (version 2.0)</a>)</p>
<p>在安装nvidia-docker 2.0需要做一些准备的工作,要求如下:</p>
<ul>
<li>GNU/Linux x86_64 with kernel version &gt; 3.10</li>
<li>Docker &gt;= 1.12</li>
<li>NVIDIA GPU with Architecture &gt; Fermi (2.1)</li>
<li><a href="https://www.nvidia.com/object/unix.html" target="_blank" rel="noopener">NVIDIA drivers</a>~= 361.93 (untested on older versions)</li>
</ul>
<p>Your driver version might limit your CUDA capabilities (<a href="https://github.com/nvidia/nvidia-docker/wiki/CUDA#requirements">see CUDA requirements</a>)</p>
<p>简单的描述下安装的过程:</p>
<p>CentOS 7 (docker-ce), RHEL 7.4/7.5 (docker-ce), Amazon Linux 1/2</p>
<figure class="highlight awk"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># If you have nvidia-docker 1.0 installed: we need to remove it and all existing GPU containers</span></span><br><span class="line">docker volume ls -q -f driver=nvidia-docker | xargs -r -I&#123;&#125; -n1 docker ps -q -a -f volume=&#123;&#125; | xargs -r docker rm -f</span><br><span class="line">sudo yum remove nvidia-docker</span><br><span class="line"></span><br><span class="line"><span class="comment"># Add the package repositories</span></span><br><span class="line">distribution=$(. <span class="regexp">/etc/</span>os-release;echo <span class="variable">$ID</span><span class="variable">$VERSION_ID</span>)</span><br><span class="line">curl -s -L https:<span class="regexp">//</span>nvidia.github.io<span class="regexp">/nvidia-docker/</span><span class="variable">$distribution</span><span class="regexp">/nvidia-docker.repo | \</span></span><br><span class="line"><span class="regexp">  sudo tee /</span>etc<span class="regexp">/yum.repos.d/</span>nvidia-docker.repo</span><br><span class="line"></span><br><span class="line"><span class="comment"># Install nvidia-docker2 and reload the Docker daemon configuration</span></span><br><span class="line">sudo yum install -y nvidia-docker2</span><br><span class="line">sudo pkill -SIGHUP dockerd</span><br><span class="line"></span><br><span class="line"><span class="comment"># Test nvidia-smi with the latest official CUDA image</span></span><br><span class="line">docker run --runtime=nvidia --rm nvidia<span class="regexp">/cuda:9.0-base nvidia-smi</span></span><br></pre></td></tr></table></figure>
<p>nvidia-docker 2.0安装完成之后，需要配置docker的runtime为<code>nvidia-container-runtime</code>。具体的内容如下:</p>
<figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">"default-runtime"</span>:<span class="string">"nvidia"</span>,</span><br><span class="line">    <span class="attr">"runtimes"</span>: &#123;</span><br><span class="line">        <span class="attr">"nvidia"</span>: &#123;</span><br><span class="line">          <span class="attr">"path"</span>: <span class="string">"/usr/bin/nvidia-container-runtime"</span>,</span><br><span class="line">          <span class="attr">"runtimeArgs"</span>: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>重新启动docker服务:</p>
<figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">systemctl restart docker</span></span><br></pre></td></tr></table></figure>
<p>注意:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">If you have <span class="selector-tag">a</span> custom /etc/docker/daemon<span class="selector-class">.json</span>, the nvidia-docker2 package might override it.</span><br></pre></td></tr></table></figure>
<h2 id="GPU-on-kubernetes"><a href="#GPU-on-kubernetes" class="headerlink" title="GPU on kubernetes"></a>GPU on kubernetes</h2><p>简述的描述下现在kubernetes对GPU的支持情况。kubernetes在<code>1.6</code>版本就开始对<code>nvidia GPU</code>的支持，并且仍然在不断的优化改进中。kubernetes对<code>AMD GPU</code>的支持是在<code>1.9</code>版本才支持。但是现在kubernetes仍然还没有支持<code>多容器使用同一块GPU卡的情况</code>。这样就会照成GPU资源的浪费。</p>
<p>kubernetes 官方文档描述:</p>
<figure class="highlight livecodeserver"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Each container can request <span class="literal">one</span> <span class="keyword">or</span> more GPUs. It is <span class="keyword">not</span> possible <span class="built_in">to</span> request <span class="keyword">a</span> fraction <span class="keyword">of</span> <span class="keyword">a</span> GPU.</span><br></pre></td></tr></table></figure>
<p>nvidia-docker2.0 已经安装完成了，继续，下来就是如果在kubernetes上使用了。kubernetes要调度GPU 有这么几点要求:</p>
<ul>
<li>开启kubernetes对GPU的支持。(在1.10之前需要指定<code>--feature-gates=&quot;DevicePlugins=true&quot;</code>。1.10之后就不需要在指定了)。</li>
<li>在kubernetes计算节点安装<code>GPU drivers</code>(安装方法:<a href="https://xigang.github.io/2018/09/01/gpu/" target="_blank" rel="noopener">GPU Container on Kubernetes</a>)及<code>device plugin</code>。</li>
</ul>
<p>对<code>Device Plugins</code>进行下简单的描述:</p>
<p>从kuberntes 1.8版本开始提供一套<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/device-plugin.md">device plugin framework</a>来为服务厂商接入它们自己的资源(GPUs, High-performance NICs, FPGAs)。而不需要更改kubernetes的源码。</p>
<p>现在我们只关心Nvidia-GPU，让我们来部署<code>GPU device plugin</code>, 具体的部署流程流程如下:</p>
<p>nvidia-docker-plugin.yml</p>
<figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">apiVersion:</span> <span class="string">extensions/v1beta1</span></span><br><span class="line"><span class="attr">kind:</span> <span class="string">DaemonSet</span></span><br><span class="line"><span class="attr">metadata:</span></span><br><span class="line"><span class="attr">  name:</span> <span class="string">nvidia-device-plugin-daemonset</span></span><br><span class="line"><span class="attr">  namespace:</span> <span class="string">kube-system</span></span><br><span class="line"><span class="attr">spec:</span></span><br><span class="line"><span class="attr">  template:</span></span><br><span class="line"><span class="attr">    metadata:</span></span><br><span class="line">      <span class="comment"># Mark this pod as a critical add-on; when enabled, the critical add-on scheduler</span></span><br><span class="line">      <span class="comment"># reserves resources for critical add-on pods so that they can be rescheduled after</span></span><br><span class="line">      <span class="comment"># a failure.  This annotation works in tandem with the toleration below.</span></span><br><span class="line"><span class="attr">      annotations:</span></span><br><span class="line">        <span class="string">scheduler.alpha.kubernetes.io/critical-pod:</span> <span class="string">""</span></span><br><span class="line"><span class="attr">      labels:</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nvidia-device-plugin-ds</span></span><br><span class="line"><span class="attr">    spec:</span></span><br><span class="line"><span class="attr">      tolerations:</span></span><br><span class="line">      <span class="comment"># Allow this pod to be rescheduled while the node is in "critical add-ons only" mode.</span></span><br><span class="line">      <span class="comment"># This, along with the annotation above marks this pod as a critical add-on.</span></span><br><span class="line"><span class="attr">      - key:</span> <span class="string">CriticalAddonsOnly</span></span><br><span class="line"><span class="attr">        operator:</span> <span class="string">Exists</span></span><br><span class="line"><span class="attr">      containers:</span></span><br><span class="line"><span class="attr">      - image:</span> <span class="string">nvidia/k8s-device-plugin:1.9</span></span><br><span class="line"><span class="attr">        name:</span> <span class="string">nvidia-device-plugin-ctr</span></span><br><span class="line"><span class="attr">        securityContext:</span></span><br><span class="line"><span class="attr">          allowPrivilegeEscalation:</span> <span class="literal">false</span></span><br><span class="line"><span class="attr">          capabilities:</span></span><br><span class="line"><span class="attr">            drop:</span> <span class="string">["ALL"]</span></span><br><span class="line"><span class="attr">        volumeMounts:</span></span><br><span class="line"><span class="attr">          - name:</span> <span class="string">device-plugin</span></span><br><span class="line"><span class="attr">            mountPath:</span> <span class="string">/var/lib/kubelet/device-plugins</span></span><br><span class="line"><span class="attr">      volumes:</span></span><br><span class="line"><span class="attr">        - name:</span> <span class="string">device-plugin</span></span><br><span class="line"><span class="attr">          hostPath:</span></span><br><span class="line"><span class="attr">            path:</span> <span class="string">/var/lib/kubelet/device-plugins</span></span><br></pre></td></tr></table></figure>
<p>创建GPU-device-plugin资源:</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">kubectl</span> <span class="selector-tag">create</span> <span class="selector-tag">-f</span> <span class="selector-tag">nvidia-docker-plugin</span><span class="selector-class">.yml</span></span><br></pre></td></tr></table></figure>
<p>创建成功之后，在每台GPU机器上会有<code>nvidia-device-plugin-daemonset</code>的资源。</p>
<p>现在所有的准备工作都完成了。让我们来测试GPU能否正常的调度到GPU机器上吧。测试的gpu-pod资源mainfest内容如下:</p>
<p>nvidia-docker2-gpu-pod.yml</p>
<figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: v1</span><br><span class="line"><span class="attribute">kind</span>: Pod</span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: cuda-vector-add</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">restartPolicy</span>: OnFailure</span><br><span class="line">  <span class="attribute">containers</span>:</span><br><span class="line">    - <span class="attribute">name</span>: cuda-vector-add</span><br><span class="line">      <span class="attribute">image</span>: <span class="string">"k8s.gcr.io/cuda-vector-add:v0.1"</span></span><br><span class="line">      <span class="attribute">resources</span>:</span><br><span class="line">        <span class="attribute">limits</span>:</span><br><span class="line">          nvidia.com/<span class="attribute">gpu</span>: <span class="number">1</span></span><br><span class="line">  <span class="attribute">nodeSelector</span>:</span><br><span class="line">    <span class="attribute">accelerator</span>: nvidia-tesla-k80 # or nvidia-tesla-k80 etc.</span><br></pre></td></tr></table></figure>
<p>根据上面的文件创建资源并进行校验:</p>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">kubectl</span> <span class="selector-tag">create</span> <span class="selector-tag">-f</span> <span class="selector-tag">nvidia-docker2-gpu-pod</span><span class="selector-class">.yml</span></span><br></pre></td></tr></table></figure>
<p>进入到容器中查看相关的设备及cuda库是否挂载到了容器中，并且验证我们给容器分配的只有一块卡。</p>
<p><div align="left"><br><img src="http://p0.qhimg.com/t01a3a19b26a682dfb0.png" width="800" height="350" alt="namespace"></div></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在kubernetes中使用<code>nvidia-docker 1.0</code>的弊端在于，在使用资源对象进行资源创建的时候，需要在配置中将<code>GPU Driver</code>已volume的方式挂载到容器中，这步需要人为的进行干涉。但是使用<code>nvidia-docker 2.0</code>的方式不要在在配置中指定<code>GPU Driver</code>的位置。完全有<code>device plugin</code>来做这件事。方便省事儿。并且kubernetes对外提供了<code>device plugin</code>的接口。也方便各个厂商来对自家的资源实现对k8s的无缝接入。不仅仅是<code>device plugin</code>, kubernetes对容器运行时，也提供了同样的interface的方式，来对外提供对各家运行时的支持。这也就是kubernetes扩展性的强大之处吧。</p>
</div><div class="tags"><a href="/tags/kubernetes/">kubernetes</a><a href="/tags/docker/">docker</a></div><div class="post-nav"><a class="pre" href="/2018/11/08/nvidia-container-runtime/">深入理解 Nvidia-docker2.0</a><a class="next" href="/2018/10/14/namespace-md/">浅谈 Linux Namespace</a></div><div id="container"></div><link rel="stylesheet" href="/css/default.css?v=0.0.0"><script src="/js/gitment.browser.js?v=0.0.0"></script><script>var gitment = new Gitment({
  owner: 'xigang',
  repo: 'https://github.com/xigang/gitment-comments',
  oauth: {
    client_id: '86d1945e3a9358946043',
    client_secret: '304f48ee3394ae5dab75d19a966506e170d850f6',
  },
})
gitment.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://github.com/xigang"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/云计算/">云计算</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/存储/">存储</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/微服务/">微服务</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/kubernetes/" style="font-size: 15px;">kubernetes</a> <a href="/tags/ceph/" style="font-size: 15px;">ceph</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/etcd/" style="font-size: 15px;">etcd</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/microservices/" style="font-size: 15px;">microservices</a> <a href="/tags/kube-dns/" style="font-size: 15px;">kube-dns</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/11/24/kube-dns/">Kubernetes DNS 介绍</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/08/nvidia-container-runtime/">深入理解 Nvidia-docker2.0</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/11/05/nvidia-docker2/">Nvidia-Docker2在kubernetes上实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/14/namespace-md/">浅谈 Linux Namespace</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/16/replicaset/">Kube-Controller-manager之Replicaset Controller源码解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/08/deployment/">Kube-Controller-manager之Deployment Controller源码解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/01/gpu/">GPU Container on Kubernetes</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/19/kong/">Api-Gateway Kong与容器服务</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/18/etcd-back/">Etcd集群备份及容灾恢复</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/08/cgroups/">浅谈Cgroups</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://gogap.cn/" title="gogap" target="_blank">gogap</a><ul></ul><a href="http://www.0x7c00.net/" title="31744" target="_blank">31744</a><ul></ul><a href="https://www.opsdev.cn/" title="360opsdev" target="_blank">360opsdev</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">xigang's home.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>
<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>nvidia-docker2在kubernetes上实践 | xigang's home</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">nvidia-docker2在kubernetes上实践</h1><a id="logo" href="/.">xigang's home</a><p class="description">简单不先于复杂，而是在复杂之后</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">nvidia-docker2在kubernetes上实践</h1><div class="post-meta">Nov 5, 2018</div><div class="post-content"><p>现在公司线上所有的k8s集群对GPU资源的使用都是<code>nvidia-docker 1.0</code>(历史遗留问题)。并且还专门写了篇文章记录是如何使用的<a href="https://xigang.github.io/2018/09/01/gpu/" target="_blank" rel="noopener">GPU Container on Kubernetes</a>。但是现在的kubernetes1.9推荐使用<code>device plugin</code>的方式来对接外部厂商的资源。这样所有的厂商的资源就不要kubernetes去特定的支持，而是各服务厂商只要按照<code>kubernetes</code>提供的<a href="https://kubernetes.io/docs/concepts/extend-kubernetes/compute-storage-net/device-plugins/" target="_blank" rel="noopener">device plugin</a>实现自己的一套就可以了。今天就针对<code>nvidia-docker2.0</code> 进行了下测试。在此做下记录。</p>
<h2 id="实验环境"><a href="#实验环境" class="headerlink" title="实验环境"></a>实验环境</h2><ul>
<li>CentOS Linux release 7.2.1511 (Core)</li>
<li>kuberntes: 1.9</li>
<li>GPU: nvidia-tesla-k80</li>
</ul>
<h2 id="Installation-version-2-0"><a href="#Installation-version-2-0" class="headerlink" title="Installation (version 2.0)"></a>Installation (version 2.0)</h2><p>直接参照官方的安装教程:<a href="https://github.com/nvidia/nvidia-docker/wiki/Installation-(version-2.0">Installation (version 2.0)</a>)</p>
<p>在安装nvidia-docker 2.0需要做一些准备的工作,要求如下:</p>
<ul>
<li>GNU/Linux x86_64 with kernel version &gt; 3.10</li>
<li>Docker &gt;= 1.12</li>
<li>NVIDIA GPU with Architecture &gt; Fermi (2.1)</li>
<li><a href="https://www.nvidia.com/object/unix.html" target="_blank" rel="noopener">NVIDIA drivers</a>~= 361.93 (untested on older versions)</li>
</ul>
<p>Your driver version might limit your CUDA capabilities (<a href="https://github.com/nvidia/nvidia-docker/wiki/CUDA#requirements">see CUDA requirements</a>)</p>
<p>简单的描述下安装的过程:</p>
<p>CentOS 7 (docker-ce), RHEL 7.4/7.5 (docker-ce), Amazon Linux 1/2</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># If you have nvidia-docker 1.0 installed: we need to remove it and all existing GPU containers</span><br><span class="line">docker volume ls -q -f driver=nvidia-docker | xargs -r -I&#123;&#125; -n1 docker ps -q -a -f volume=&#123;&#125; | xargs -r docker rm -f</span><br><span class="line">sudo yum remove nvidia-docker</span><br><span class="line"></span><br><span class="line"># Add the package repositories</span><br><span class="line">distribution=$(. /etc/os-release;echo $ID$VERSION_ID)</span><br><span class="line">curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.repo | \</span><br><span class="line">  sudo tee /etc/yum.repos.d/nvidia-docker.repo</span><br><span class="line"></span><br><span class="line"># Install nvidia-docker2 and reload the Docker daemon configuration</span><br><span class="line">sudo yum install -y nvidia-docker2</span><br><span class="line">sudo pkill -SIGHUP dockerd</span><br><span class="line"></span><br><span class="line"># Test nvidia-smi with the latest official CUDA image</span><br><span class="line">docker run --runtime=nvidia --rm nvidia/cuda:9.0-base nvidia-smi</span><br></pre></td></tr></table></figure>
<p>nvidia-docker 2.0安装完成之后，需要配置docker的runtime为<code>nvidia-container-runtime</code>。具体的内容如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    &quot;default-runtime&quot;:&quot;nvidia&quot;,</span><br><span class="line">    &quot;runtimes&quot;: &#123;</span><br><span class="line">        &quot;nvidia&quot;: &#123;</span><br><span class="line">          &quot;path&quot;: &quot;/usr/bin/nvidia-container-runtime&quot;,</span><br><span class="line">          &quot;runtimeArgs&quot;: []</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;,</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>重新启动docker服务:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl restart docker</span><br></pre></td></tr></table></figure>
<p>注意:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">If you have a custom /etc/docker/daemon.json, the nvidia-docker2 package might override it.</span><br></pre></td></tr></table></figure>
<h2 id="GPU-on-kubernetes"><a href="#GPU-on-kubernetes" class="headerlink" title="GPU on kubernetes"></a>GPU on kubernetes</h2><p>简述的描述下现在kubernetes对GPU的支持情况。kubernetes在<code>1.6</code>版本就开始对<code>nvidia GPU</code>的支持，并且仍然在不断的优化改进中。kubernetes对<code>AMD GPU</code>的支持是在<code>1.9</code>版本才支持。但是现在kubernetes仍然还没有支持<code>多容器使用同一块GPU卡的情况</code>。这样就会照成GPU资源的浪费。</p>
<p>kubernetes 官方文档描述:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Each container can request one or more GPUs. It is not possible to request a fraction of a GPU.</span><br></pre></td></tr></table></figure>
<p>nvidia-docker2.0 已经安装完成了，继续，下来就是如果在kubernetes上使用了。kubernetes要调度GPU 有这么几点要求:</p>
<ul>
<li>开启kubernetes对GPU的支持。(在1.10之前需要指定<code>--feature-gates=&quot;DevicePlugins=true&quot;</code>。1.10之后就不需要在指定了)。</li>
<li>在kubernetes计算节点安装<code>GPU drivers</code>(安装方法:<a href="https://xigang.github.io/2018/09/01/gpu/" target="_blank" rel="noopener">GPU Container on Kubernetes</a>)及<code>device plugin</code>。</li>
</ul>
<p>对<code>Device Plugins</code>进行下简单的描述:</p>
<p>从kuberntes 1.8版本开始提供一套<a href="https://github.com/kubernetes/community/blob/master/contributors/design-proposals/resource-management/device-plugin.md">device plugin framework</a>来为服务厂商接入它们自己的资源(GPUs, High-performance NICs, FPGAs)。而不需要更改kubernetes的源码。</p>
<p>现在我们只关心Nvidia-GPU，让我们来部署<code>GPU device plugin</code>, 具体的部署流程流程如下:</p>
<p>nvidia-docker-plugin.yml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: extensions/v1beta1</span><br><span class="line">kind: DaemonSet</span><br><span class="line">metadata:</span><br><span class="line">  name: nvidia-device-plugin-daemonset</span><br><span class="line">  namespace: kube-system</span><br><span class="line">spec:</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      # Mark this pod as a critical add-on; when enabled, the critical add-on scheduler</span><br><span class="line">      # reserves resources for critical add-on pods so that they can be rescheduled after</span><br><span class="line">      # a failure.  This annotation works in tandem with the toleration below.</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: &quot;&quot;</span><br><span class="line">      labels:</span><br><span class="line">        name: nvidia-device-plugin-ds</span><br><span class="line">    spec:</span><br><span class="line">      tolerations:</span><br><span class="line">      # Allow this pod to be rescheduled while the node is in &quot;critical add-ons only&quot; mode.</span><br><span class="line">      # This, along with the annotation above marks this pod as a critical add-on.</span><br><span class="line">      - key: CriticalAddonsOnly</span><br><span class="line">        operator: Exists</span><br><span class="line">      containers:</span><br><span class="line">      - image: nvidia/k8s-device-plugin:1.9</span><br><span class="line">        name: nvidia-device-plugin-ctr</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            drop: [&quot;ALL&quot;]</span><br><span class="line">        volumeMounts:</span><br><span class="line">          - name: device-plugin</span><br><span class="line">            mountPath: /var/lib/kubelet/device-plugins</span><br><span class="line">      volumes:</span><br><span class="line">        - name: device-plugin</span><br><span class="line">          hostPath:</span><br><span class="line">            path: /var/lib/kubelet/device-plugins</span><br></pre></td></tr></table></figure>
<p>创建GPU-device-plugin资源:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f nvidia-docker-plugin.yml</span><br></pre></td></tr></table></figure>
<p>创建成功之后，在每台GPU机器上会有<code>nvidia-device-plugin-daemonset</code>的资源。</p>
<p>现在所有的准备工作都完成了。让我们来测试GPU能否正常的调度到GPU机器上吧。测试的gpu-pod资源mainfest内容如下:</p>
<p>nvidia-docker2-gpu-pod.yml</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: cuda-vector-add</span><br><span class="line">spec:</span><br><span class="line">  restartPolicy: OnFailure</span><br><span class="line">  containers:</span><br><span class="line">    - name: cuda-vector-add</span><br><span class="line">      image: &quot;k8s.gcr.io/cuda-vector-add:v0.1&quot;</span><br><span class="line">      resources:</span><br><span class="line">        limits:</span><br><span class="line">          nvidia.com/gpu: 1</span><br><span class="line">  nodeSelector:</span><br><span class="line">    accelerator: nvidia-tesla-k80 # or nvidia-tesla-k80 etc.</span><br></pre></td></tr></table></figure>
<p>根据上面的文件创建资源并进行校验:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl create -f nvidia-docker2-gpu-pod.yml</span><br></pre></td></tr></table></figure>
<p>进入到容器中查看相关的设备及cuda库是否挂载到了容器中，并且验证我们给容器分配的只有一块卡。</p>
<p><div align="left"><br><img src="http://p0.qhimg.com/t01a3a19b26a682dfb0.png" width="800" height="350" alt="namespace"></div></p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>在kubernetes中使用<code>nvidia-docker 1.0</code>的弊端在于，在使用资源对象进行资源创建的时候，需要在配置中将<code>GPU Driver</code>已volume的方式挂载到容器中，这步需要人为的进行干涉。但是使用<code>nvidia-docker 2.0</code>的方式不要在在配置中指定<code>GPU Driver</code>的位置。完全有<code>device plugin</code>来做这件事。方便省事儿。并且kubernetes对外提供了<code>device plugin</code>的接口。也方便各个厂商来对自家的资源实现对k8s的无缝接入。不仅仅是<code>device plugin</code>, kubernetes对容器运行时，也提供了同样的interface的方式，来对外提供对各家运行时的支持。这也就是kubernetes扩展性的强大之处吧。</p>
</div><div class="tags"><a href="/tags/kubernetes/">kubernetes</a><a href="/tags/nvidia-docker/">nvidia-docker</a><a href="/tags/docker/">docker</a></div><div class="post-nav"><a class="next" href="/2018/10/14/namespace-md/">浅谈 Linux Namespace</a></div></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.google.com/search" method="get" accept-charset="utf-8" target="_blank"><input type="text" name="q" maxlength="20" placeholder="Search"/><input type="hidden" name="sitesearch" value="https://github.com/xigang"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/kubernetes/" style="font-size: 15px;">kubernetes</a> <a href="/tags/linux/" style="font-size: 15px;">linux</a> <a href="/tags/etcd/" style="font-size: 15px;">etcd</a> <a href="/tags/machine-learning/" style="font-size: 15px;">machine-learning</a> <a href="/tags/nvidia-docker/" style="font-size: 15px;">nvidia-docker</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/microservices/" style="font-size: 15px;">microservices</a> <a href="/tags/kernel/" style="font-size: 15px;">kernel</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2018/11/05/nvidia-docker2/">nvidia-docker2在kubernetes上实践</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/10/14/namespace-md/">浅谈 Linux Namespace</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/16/replicaset/">kube-controller-manager之Replicaset controller源码解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/08/deployment/">kube-controller-manager之Deployment Controller源码解析</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/09/01/gpu/">GPU Container on Kubernetes</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/19/kong/">api-gateway kong与容器服务</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/08/18/etcd-back/">etcd集群备份及容灾恢复</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/07/08/cgroups/">浅谈Cgroups</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/30/lxcfs/">使用lxcfs对docker容器隔离</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/06/04/controller-manager/">kube-controller-manaer解析之启动流程</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://gogap.cn/" title="gogap" target="_blank">gogap</a><ul></ul><a href="http://sixianed.com/" title="sixianed" target="_blank">sixianed</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2018 <a href="/." rel="nofollow">xigang's home.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>
<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>A Deep Dive Into Kubernetes Metrics - Container Resource Metrics | xigang's home</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">A Deep Dive Into Kubernetes Metrics - Container Resource Metrics</h1><a id="logo" href="/.">xigang's home</a><p class="description">Do it right or don't do it at all</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">A Deep Dive Into Kubernetes Metrics - Container Resource Metrics</h1><div class="post-meta">Apr 9, 2019<span> | </span><span class="category"><a href="/categories/日志监控/">日志监控</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><p>This time I will be looking at the metrics at the container level. These are the metrics as reported by cAdvisor.</p>
<a id="more"></a>
<h2 id="Container-Metrics-from-cAdvisor"><a href="#Container-Metrics-from-cAdvisor" class="headerlink" title="Container Metrics from cAdvisor"></a>Container Metrics from cAdvisor</h2><p>The <a href="https://github.com/google/cadvisor">cAdvisor</a> project from Google started as a stand-alone project for gathering resource and performance metrics from running containers on a node. In Kubernetes, the cAdvisor is embedded into the kubelet. This is the process that controls all the container on every node in the cluster. This is handy as you don’t need to run yet another process in every node to gather container metrics.</p>
<p>The kublet exposes all of it’s runtime metrics, and all of the cAdvisor metrics, on a /metrics endpoint in the Prometheus exposition format.</p>
<p>The “container” metrics that are exposed from cAdvisor are ultimately the metrics reported by the underlying Linux cgroup implementation. Just as with the node metrics, they are numerous and detailed. However, we are concerned with container use of resources provided by the underlying node. Specifically we are interested in CPU, memory, network and disk. When dealing with resources, again, its best to use the USE method when selecting the reporting on these metrics.</p>
<h2 id="The-USE-method-and-Container-Metrics"><a href="#The-USE-method-and-Container-Metrics" class="headerlink" title="The USE method and Container Metrics"></a>The USE method and Container Metrics</h2><p>As a quick reminder, the USE method stands for Utilization, Saturation and Errors. Please refer to <a href="https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-part-2-c869581e9f29" target="_blank" rel="noopener">part</a> 2 of this series for an in-depth treatment of this method.</p>
<p>Because the source of these metrics changes from the node (node_exporter) to the container (cAdvisor) the names of the metrics will also change. Additionally each of the metrics will be reports for all of the containers in your cluster. Using the sum method in Prometheus will be necessary to get an overall view of your application.</p>
<p>Before I start talking about the individual resource metrics we need to talk about a feature in Kubernetes that will make calculating saturation a bit easier. This feature is resource “requests” and “limits”.</p>
<h2 id="Kubernetes-Requests-and-Limits"><a href="#Kubernetes-Requests-and-Limits" class="headerlink" title="Kubernetes Requests and Limits"></a>Kubernetes Requests and Limits</h2><p>At the heart of the Kubernetes system is a scheduler that places containers on nodes. Much like packing a bunch of different sized boxes with different sized items, the scheduler needs to know the capacity of the nodes and the sizes of the containers being placed on those nodes. Without knowing the “size” of the containers you can easily over-provision the nodes in your cluster causing performance problems due to overcrowding.</p>
<p>Requests and limits are applied to the container specification as part of a deployment. As of Kubernetes 1.10 two resources types can have requests and limits set; CPU and Memory. CPU is specified as fractions of a CPU or core (down to 1/1000th) and memory is specified in bytes.</p>
<p>A <code>request</code> is a bid for the minimum amount of that resource your container will need. A request doesn’t say how much of a resource you will be using, just how much you will need. You are telling the scheduler just how many resources your container needs to do its job. Requests are used for scheduling by the Kubernetes scheduler. For CPU requests they are also used to configure how the containers are scheduled by the Linux kernel. More on that in another post.</p>
<p>A <code>limit</code> is the very maximum amount of that resource your container will ever use. Limits must be greater than or equal to requests. If you set only limits, the request will be the same as the limit.</p>
<p>Limits allow the container some headroom to surge past the resource request. Limits give you one knob to over-provision containers on a node as limits are not accounted for by the Kubernetes scheduler. That being said, if your container exceeds your limits the action depends on the resource; you will be throttled if you exceed the CPU limit, and killed if you exceed the memory limit.</p>
<p>Running with resource requests and limits is a “<a href="https://kubernetes.io/blog/2016/08/security-best-practices-kubernetes-deployment/" target="_blank" rel="noopener">Security Best Practice</a>”:</p>
<p><code>An option of running resource-unbound containers puts your system in risk of DoS or “noisy neighbor” scenarios. To prevent and minimize those risks you should define resource quotas.</code></p>
<p>As soon as you put quotas on namespace, you will be forced to apply requests and limits to every container in that namespace.</p>
<h2 id="Container-CPU-Utilization-Saturation-and-Errors"><a href="#Container-CPU-Utilization-Saturation-and-Errors" class="headerlink" title="Container CPU Utilization, Saturation, and Errors"></a>Container CPU Utilization, Saturation, and Errors</h2><p>For CPU utilization Kubernetes gives us just three metrics for each container</p>
<p>1.<code>container_cpu_user_seconds_total</code> — The total amount of “user” time (i.e. time spent not in the kernel)<br>2.<code>container_cpu_system_seconds_total</code> — The total amount of “system” time (i.e. time spent in the kernel)<br>3.<code>container_cpu_usage_seconds_total</code> — The sum of the above. Prior to Kubernetes 1.9 this is reported for every CPU in all node. That changed in 1.1.0</p>
<p>All of these metrics are counters and need to have a rate applied to them. This query will give us the number of cores that are being used by each container. For all the containers of that name across the system:</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(<span class="name">rate</span>(<span class="name">container_cpu_usage_seconds_total</span>[<span class="number">5</span>m]))by (<span class="name">container_name</span>)</span><br></pre></td></tr></table></figure>
<div align="left"><br><img src="http://p0.qhimg.com/t01b96920a6aa4d17a6.png" width="800" height="600" alt="container-resosurce-metrics"><br></div>


<p>when running with CPU limits calculating saturation becomes much easier as you have defined what the upper limit of CPU usage can be. When a container exceeds its CPU limits, the Linux runtime will “throttle” the container and record the amount of time it was throttled in the series container_cpu_cfs_throttled_seconds_total. This is tracked per-container again as a counter so take a rate:</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(<span class="name">rate</span>(<span class="name">container_cpu_cfs_throttled_seconds_total</span>[<span class="number">5</span>m])) by (<span class="name">container_name</span>)</span><br></pre></td></tr></table></figure>
<p>This is an important metric to keep track of when running with CPU limits (which should always be the case!).</p>
<p>Much like the node_exporter, cAdvisor does not expose CPU errors.</p>
<h2 id="Memory-Utilization-Saturation-and-Errors"><a href="#Memory-Utilization-Saturation-and-Errors" class="headerlink" title="Memory Utilization, Saturation and Errors"></a>Memory Utilization, Saturation and Errors</h2><p>The memory metrics that are tracked in the cAdvisor are a subset of the 43 memory metrics exposed from the node_exporter. Here are the container memory metrics:</p>
<figure class="highlight ocaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">container_memory_cache -- <span class="type">Number</span> <span class="keyword">of</span> <span class="built_in">bytes</span> <span class="keyword">of</span> page cache memory.</span><br><span class="line">container_memory_rss -- <span class="type">Size</span> <span class="keyword">of</span> <span class="type">RSS</span> <span class="keyword">in</span> <span class="built_in">bytes</span>.</span><br><span class="line">container_memory_swap -- <span class="type">Container</span> swap usage <span class="keyword">in</span> <span class="built_in">bytes</span>.</span><br><span class="line">container_memory_usage_bytes -- <span class="type">Current</span> memory usage <span class="keyword">in</span> <span class="built_in">bytes</span>,including all memory regardless <span class="keyword">of</span> <span class="keyword">when</span> it was accessed.</span><br><span class="line">container_memory_max_usage_bytes -- <span class="type">Maximum</span> memory usage recorded <span class="keyword">in</span> <span class="built_in">bytes</span>.</span><br><span class="line">container_memory_working_set_bytes -- <span class="type">Current</span> working set <span class="keyword">in</span> <span class="built_in">bytes</span>.</span><br><span class="line">container_memory_failcnt -- <span class="type">Number</span> <span class="keyword">of</span> memory usage hits limits.</span><br><span class="line">container_memory_failures_total -- <span class="type">Cumulative</span> count <span class="keyword">of</span> memory allocation failures.</span><br></pre></td></tr></table></figure>
<p>You might think that memory utilization is easily tracked with <code>container_memory_usage_bytes</code>, however, this metric also includes cached (think filesystem cache) items that can be evicted under memory pressure. The better metric is <code>container_memory_working_set_bytes</code> as this is what the OOM killer is watching for.</p>
<p>To calculate container memory utilization we use:</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sum(<span class="name">container_memory_working_set_bytes</span>&#123;name!~<span class="string">"POD"</span>&#125;) by (<span class="name">name</span>)</span><br></pre></td></tr></table></figure>
<p>In the above query, we need to exclude the container who’s name contains “POD”. This is parent cgroup for this container and will track stats for all the containers in the pod.</p>
<p>Container memory saturation gets easier when running with memory limits (sensing a theme here?). We will define saturation as the amount of available memory from the limit:</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum(<span class="name">container_memory_working_set_bytes</span>) by (<span class="name">container_name</span>) / sum(<span class="name">label_join</span>(<span class="name">kube_pod_container_resource_limits_memory_bytes</span>,</span><br><span class="line">    <span class="string">"container_name"</span>, <span class="string">""</span>, <span class="string">"container"</span>)) by (<span class="name">container_name</span>)</span><br></pre></td></tr></table></figure>
<p>Here we have to join two series, one from cAdvisor and one from kube-state-metrics. Unfortunately, the container name labels don’t align, but PromQL helps with the <code>label_join</code> here.</p>
<p>memory errors are not exposed by the kubelet.</p>
<h2 id="Disk-Utilization-Saturation-and-Errors"><a href="#Disk-Utilization-Saturation-and-Errors" class="headerlink" title="Disk Utilization, Saturation, and Errors"></a>Disk Utilization, Saturation, and Errors</h2><p>When dealing with disk I/O these we start with tracking all disk utilization by looking and both reads and writes. cAdvisor has series for <code>container_fs_io_time_seconds_total</code> and <code>container_fs_io_time_weighted_seconds_total</code>. These should track the similar metrics at the node level, however in my installation these are always zero.</p>
<p>The most basic disk I/O utilization are bytes read/written:</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum(<span class="name">rate</span>(<span class="name">container_fs_writes_bytes_total</span>[<span class="number">5</span>m])) by (<span class="name">container_name</span>,device)</span><br><span class="line">sum(<span class="name">rate</span>(<span class="name">container_fs_reads_bytes_total</span>[<span class="number">5</span>m])) by (<span class="name">container_name</span>,device)</span><br></pre></td></tr></table></figure>
<p>Sum these to get an overall disk I/O utilization, per container.</p>
<p>The kubelet does not expose enough detail to have a meaningful query for container disk saturation or errors.</p>
<h2 id="Network-Utilization-Saturation-and-Errors"><a href="#Network-Utilization-Saturation-and-Errors" class="headerlink" title="Network Utilization, Saturation and Errors"></a>Network Utilization, Saturation and Errors</h2><p>Network utilization at the container level you can choose between measuring in bytes or packets for both send and receive. This query is a little different in that all the network accounting happens at the Pod level, not at the container!</p>
<p>This query will show the network utilization for each pod, by pod name:</p>
<figure class="highlight lisp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sum(<span class="name">rate</span>(<span class="name">container_network_receive_bytes_total</span>[<span class="number">5</span>m])) by (<span class="name">name</span>)</span><br><span class="line">sum(<span class="name">rate</span>(<span class="name">container_network_transmit_bytes_total</span>[<span class="number">5</span>m])) by (<span class="name">name</span>)</span><br></pre></td></tr></table></figure>
<p>Again, saturation for a network is ill-defined without knowing what the max network bandwidth is. You might be able to use packets dropped as proxy:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">container_network_receive_packets_dropped_total</span><br><span class="line">container_network_transmit_packets_dropped_total</span><br></pre></td></tr></table></figure>
<p>cAdvisor also show the number of errors with the series:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">container_network_receive_errors_total</span><br><span class="line">container_network_transmit_errors_total</span><br></pre></td></tr></table></figure>
<h2 id="Wrapping-Up"><a href="#Wrapping-Up" class="headerlink" title="Wrapping Up"></a>Wrapping Up</h2><p>The kubelet, by using cAdvisor, exposes a wealth of information about the resources for all the containers in your Kubernetes cluster. Viewing these resources through the lens of utilization, saturation and errors gives you starting point for investigation of resource constraints and capacity planning.</p>
<h2 id="reference"><a href="#reference" class="headerlink" title="reference"></a>reference</h2><ul>
<li><a href="https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-b190cc97f0f6" target="_blank" rel="noopener">A Deep Dive into Kubernetes Metrics Part Zero: Introdution</a></li>
<li><a href="https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-66936addedae" target="_blank" rel="noopener">A Deep Dive into Kubernetes Metrics — Part 1 The Node Metrics</a></li>
<li><a href="https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-part-2-c869581e9f29" target="_blank" rel="noopener">A Deep Dive into Kubernetes Metrics - Part 2 The USE Method and node_exporter Metrics</a></li>
<li><a href="https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-part-3-container-resource-metrics-361c5ee46e66" target="_blank" rel="noopener">A Deep Dive into Kubernetes Metrics — Part 3 Container Resource Metrics</a></li>
<li><a href="https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-part-4-the-kubernetes-api-server-72f1e1210770" target="_blank" rel="noopener">A Deep Dive into Kubernetes Metrics — Part 4: The Kubernetes API Server</a></li>
<li><a href="https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-part-5-etcd-metrics-6502693fa58" target="_blank" rel="noopener">A Deep Dive into Kubernetes Metrics — Part 5: etcd metrics</a></li>
<li><a href="https://blog.freshtracks.io/a-deep-dive-into-kubernetes-metrics-part-6-kube-state-metrics-14f4e7c8710b" target="_blank" rel="noopener">A Deep Dive into Kubernetes Metrics — Part 6: kube-state-metrics</a></li>
<li><a href="https://medium.com/faun/how-much-is-too-much-the-linux-oomkiller-and-used-memory-d32186f29c9d" target="_blank" rel="noopener">How much is too much? The Linux OOMKiller and “used” memory</a></li>
</ul>
</div><div class="tags"><a href="/tags/prometheus/">prometheus</a><a href="/tags/kubernetes/">kubernetes</a></div><div class="post-nav"><a class="pre" href="/2019/05/11/bosun/">Prometheus基于bosun框架进行告警</a><a class="next" href="/2019/03/15/metrics-servere/">Kubernetes Metrics-Server介绍及源码分析</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '86d1945e3a9358946043',
  clientSecret: '304f48ee3394ae5dab75d19a966506e170d850f6',
  repo: 'xigang.github.io',
  owner: 'xigang',
  admin: ['xigang'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://github.com/xigang"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/docker/">docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/etcd/">etcd</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kubernetes/">kubernetes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/microservices/">microservices</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/network/">network</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/日志监控/">日志监控</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/network/" style="font-size: 15px;">network</a> <a href="/tags/prometheus/" style="font-size: 15px;">prometheus</a> <a href="/tags/alertmanager/" style="font-size: 15px;">alertmanager</a> <a href="/tags/bosun/" style="font-size: 15px;">bosun</a> <a href="/tags/kubernetes/" style="font-size: 15px;">kubernetes</a> <a href="/tags/ceph/" style="font-size: 15px;">ceph</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/cgroup/" style="font-size: 15px;">cgroup</a> <a href="/tags/kernel/" style="font-size: 15px;">kernel</a> <a href="/tags/dns/" style="font-size: 15px;">dns</a> <a href="/tags/coredns/" style="font-size: 15px;">coredns</a> <a href="/tags/kapacitor/" style="font-size: 15px;">kapacitor</a> <a href="/tags/etcd/" style="font-size: 15px;">etcd</a> <a href="/tags/kubeflow/" style="font-size: 15px;">kubeflow</a> <a href="/tags/scheduler/" style="font-size: 15px;">scheduler</a> <a href="/tags/microservices/" style="font-size: 15px;">microservices</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/kube-dns/" style="font-size: 15px;">kube-dns</a> <a href="/tags/ipvs/" style="font-size: 15px;">ipvs</a> <a href="/tags/iptables/" style="font-size: 15px;">iptables</a> <a href="/tags/netfilter/" style="font-size: 15px;">netfilter</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/08/25/coredns/">CoreDNS源码分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/08/22/dns/">A DNS Refresher</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/28/kube-proxy-source-code/">Kube-Proxy  IPVS模式源码分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/07/21/kubernetes-service/">浅谈Kubernetes Service负载均衡实现机制</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/06/01/cgroupv2/">CGROUPS VERSION 2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/11/bosun/">Prometheus基于bosun框架进行告警</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/09/container-resource-metrics/">A Deep Dive Into Kubernetes Metrics - Container Resource Metrics</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/15/metrics-servere/">Kubernetes Metrics-Server介绍及源码分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/17/gang-scheduler/">适合AI场景的调度器 - Gang-Schedule</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/30/tensorflow/">Tensorflow结合kubeflow进行分布式训练</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://gogap.cn/" title="gogap" target="_blank">gogap</a><ul></ul><a href="http://www.0x7c00.net/" title="31744" target="_blank">31744</a><ul></ul><a href="https://www.opsdev.cn/" title="360opsdev" target="_blank">360opsdev</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">xigang's home.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>
<!DOCTYPE html><html lang="zh-CN"><head><meta http-equiv="content-type" content="text/html; charset=utf-8"><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=0" name="viewport"><meta content="yes" name="apple-mobile-web-app-capable"><meta content="black-translucent" name="apple-mobile-web-app-status-bar-style"><meta content="telephone=no" name="format-detection"><meta name="description"><title>MXNet结合kubeflow进行分布式训练 | xigang's home</title><link rel="stylesheet" type="text/css" href="/css/style.css?v=0.0.0"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/normalize/8.0.0/normalize.min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/pure-min.css"><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/pure/1.0.0/grids-responsive-min.css"><link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.7.0/css/font-awesome.min.css"><script type="text/javascript" src="//cdn.bootcss.com/jquery/3.3.1/jquery.min.js"></script><link rel="Shortcut Icon" type="image/x-icon" href="/favicon.ico"><link rel="apple-touch-icon" href="/apple-touch-icon.png"><link rel="apple-touch-icon-precomposed" href="/apple-touch-icon.png"></head><body><div class="body_container"><div id="header"><div class="site-name"><h1 class="hidden">MXNet结合kubeflow进行分布式训练</h1><a id="logo" href="/.">xigang's home</a><p class="description">Do it right or don't do it at all</p></div><div id="nav-menu"><a class="current" href="/."><i class="fa fa-home"> 首页</i></a><a href="/archives/"><i class="fa fa-archive"> 归档</i></a><a href="/about/"><i class="fa fa-user"> 关于</i></a><a href="/atom.xml"><i class="fa fa-rss"> 订阅</i></a></div></div><div class="pure-g" id="layout"><div class="pure-u-1 pure-u-md-3-4"><div class="content_container"><div class="post"><h1 class="post-title">MXNet结合kubeflow进行分布式训练</h1><div class="post-meta">Jan 17, 2019<span> | </span><span class="category"><a href="/categories/机器学习/">机器学习</a></span><script src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js" async></script><span id="busuanzi_container_page_pv"> | <span id="busuanzi_value_page_pv"></span><span> 阅读</span></span></div><div class="post-content"><p><a href="https://mxnet.incubator.apache.org/" target="_blank" rel="noopener">MXnet</a>:是灵活且高效的深度学习库。</p>
<a id="more"></a>
<h2 id="MXNet以数据并行的方式进行单机多卡训练"><a href="#MXNet以数据并行的方式进行单机多卡训练" class="headerlink" title="MXNet以数据并行的方式进行单机多卡训练"></a>MXNet以数据并行的方式进行单机多卡训练</h2><p>MXNet 支持在多CPU和GPU上进行训练。其中，这些CPU和GPU可以分布在不同的服务器上。</p>
<h4 id="如何使用"><a href="#如何使用" class="headerlink" title="如何使用"></a>如何使用</h4><p>注意: 为了使用GPU进行训练任务，需要在编译MXNet<a href=""></a>中支持GPU。比如: 在配置文件<code>config.mk</code>中设置<code>USE_CUDA=1</code>，然后进行<code>make</code>操作。 详情:<a href="http://mxnet.incubator.apache.org/install/" target="_blank" rel="noopener">http://mxnet.incubator.apache.org/install/</a></p>
<p>一台GPU机器上的每块GPU都有自己的编号(编号从0开始计数)。如果想使用某一块特定的GPU卡，即可以在代码中直接指定<code>context</code>(ctx); 也可以在命令行中传递参数<code>--gpus</code>。</p>
<p>例如: 如果想在python中使用GPU 0和GPU 2,可以使用下面的代码创建网络模型。</p>
<figure class="highlight clean"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> mxnet <span class="keyword">as</span> mx</span><br><span class="line">model = mx.model.FeedFoeward(ctx=[mx.gpu(<span class="number">0</span>), mx.gpu(<span class="number">2</span>)], ...)</span><br></pre></td></tr></table></figure>
<p>如果程序接受参数<code>--gpus</code>, 比如: <a href="https://github.com/apache/incubator-mxnet/tree/master/example/image-classification">https://github.com/apache/incubator-mxnet/tree/master/example/image-classification</a>, 那么可以尝试下面的代码:</p>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python train_mnist.py --gpus <span class="number">0</span>,<span class="number">2</span></span><br></pre></td></tr></table></figure>
<h4 id="高级用法"><a href="#高级用法" class="headerlink" title="高级用法"></a>高级用法</h4><p>如果多个GPU的计算能力不同，那么可以根据它们的计算性能来划分工作负载。比如，如果GPU 0 是 GPU 2 性能的3倍，那么可以提供一个额外的负载选项 work_load_list=[3, 1]。</p>
<p>如果所有其它超参都相同，在多个GPU上训练结果应该和单GPU上的训练结果相同。但在实际应用中，由于随机存取（随机顺序或其它augmentations），使用不同的种子初始化权重和CuDNN，结果可能不同。</p>
<p>我们可以控制梯度聚合和模型更新(如执行，训练过程)的位置，通过创建不同的<code>KVStore</code>（数据通信模块）。即可以使用<code>mx.kvstore.create(type)</code>来创建一个实例，也可以使用程序的参数<code>--kv-store type</code>来实现功能。</p>
<p>两种常用的功能:</p>
<ul>
<li><code>local</code>: 所有的梯度都拷贝到CPU内存完成聚合，同时在CPU内存上完成权值的更新并拷贝回每个GPUworker。这种方式主要在于CPU与GPU,主要的性能负载在于CPU拷贝的负载。</li>
<li><code>device</code>: 梯度聚合和权值更新都在GPU上完成。GPU之间的如果支持Peer to Peer通信（PCIe or NVLink），将避免CPU拷贝的负载，可以大大减轻CPU的负担，仅受限于通信带宽。PCIe 与NVLink通信带宽不同，NVLink具备告诉的Peer to Peer通信带宽。</li>
</ul>
<p>注意: 如果有大量的GPU(比如: &gt;=4),建议使用<code>device</code>能获取更好的性能。</p>
<h2 id="MXNet以数据并行的方式进行多机多卡训练"><a href="#MXNet以数据并行的方式进行多机多卡训练" class="headerlink" title="MXNet以数据并行的方式进行多机多卡训练"></a>MXNet以数据并行的方式进行多机多卡训练</h2><p>在介绍MXNet分布式训练之前，先介绍几个关键性的概念方便理解MXNet的分布式训练:</p>
<h4 id="进程类型"><a href="#进程类型" class="headerlink" title="进程类型"></a>进程类型</h4><p>MXNet有三种类型的进程在分布式训练过程中需要相互彼此通讯。</p>
<ul>
<li><code>Worker</code>: worker进程会对每一批次(batch_size)的数据样本进行训练。对批数据进行处理之前，workers会从servers服务器pull权重。对批处理数据处理完毕之后workers会聚合梯度数据发送给servers。(如果训练模型的工作负载比较高，建议最好不要把worker和server运行在相同的机器上)。</li>
<li><code>Server</code>: 可以运行多个server服务进程，用于存储模型参数并与worker进行通讯。</li>
<li><code>Scheduler</code>: 一个调度器,在集群中负责调度的角色。主要包含: 等待各个node节点数据的上报数据并让各个node节点知道彼此的存在并互相通讯。</li>
</ul>
<p>进程之间的关系如下图所示:</p>
<p><div align="left"><br><img src="http://p0.qhimg.com/t01c07e8ee02b5ac444.png" width="800" height="300" alt="mxnet"></div></p>
<p>工作流程:</p>
<p>1.worker, server向 scheduler 注册，获取相关的信息。<br>2.worker 从 server 端pull参数w。<br>3.worker 基于参数w 和数据计算梯度，然后 push 梯度到 server。<br>4.server 更新参数w。<br>5.反复执行 2-4 过程。</p>
<h4 id="KVStore"><a href="#KVStore" class="headerlink" title="KVStore"></a>KVStore</h4><p>KVStore是MXNet提供的一个分布式的key-value存储，用来进行数据交换。KVStore本质的实现是基于参数服务器。</p>
<ul>
<li>通过引擎来管理数据一致性,这使得参数服务器的实现变得简单，同时使得KVStore的运算可以无缝的与其他部分结合在一起。</li>
<li>使用两层的通讯结构，原理如下图所示。第一层的服务器管理单机内部的多个设备之前的通讯。第二层服务器则管理机器之间通过网络的通讯。第一层的服务器在与第二层通讯前可能合并设备之间的数据来降低网络带宽消费。同时考虑到机器内和外通讯带宽和延时的不同性，可以对其使用不同的一致性模型。例如第一层用强的一致性模型，而第二层则使用弱的一致性模型来减少同步开销。<br><div align="left"><br><img src="http://p3.qhimg.com/t017ab18230cb2f5ae0.png" width="400" height="300" alt="mxnet"></div></li>
</ul>
<p>注意: 如果想要在分布式训练中使用<code>KVStore</code>功能，需要在编译MXNet时指定<code>USE_DIST_KVSTORE=1</code>标签用于分布式训练。</p>
<p>通过调用<code>mxnet.kvstore.create()</code>函数并传递<code>dist</code>关键字参数来开启分布式训练的KVStore模式:</p>
<figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kv = mxnet<span class="selector-class">.kvstore</span><span class="selector-class">.create</span>(‘dist_sync’)</span><br></pre></td></tr></table></figure>
<p>Refer <a href="https://mxnet.incubator.apache.org/versions/master/api/python/kvstore/kvstore.html" target="_blank" rel="noopener">KVStore API</a> for more information about KVStore.</p>
<h4 id="分布式训练模式"><a href="#分布式训练模式" class="headerlink" title="分布式训练模式"></a>分布式训练模式</h4><p>当<code>KVStore</code>被创建并且包含<code>dist</code>关键参数就会开启分布式训练模式。通过使用不同类型的<code>KVStore</code>，可以启用不同的分布式培训模式。具体如下:</p>
<ul>
<li><code>dist_sync</code>: 已同步的方式进行分布式训练,在处理每批次(batch)的数据时,所有的workers需要使用相同的模型参数集合。这意味着servers参数服务需要接收来自所有workers模型参数之后，才能进行下一个批次数据的处理。因此在使用这种分布式训练方式时，server参数服务需要等到所有的worker处理完毕之后，并且如果其中的某一个worker异常，会导致整个训练的过程halts。</li>
<li><code>dist_async</code>: 已异步的方式进行分布式训练，server参数服务只要收到worker的计算梯度就会立即更新存储。这意味着哪个worker处理完当前的批次数据，就可以继续下一批次数据的处理。因此该种方式的分布式训练方式比<code>dist_sync</code>要快,但是需要花费更多的<code>epochs</code>去收敛。</li>
<li><code>dist_sync_device</code>: 该分布式训练模式与<code>dist_sync</code>训练模式相同，只是<code>dist_sync_device</code>模式会在多GPUs上进行梯度聚合和更新权重，而<code>dist_sync</code>是在CPU上进行这些操作。这种模式比<code>dist_sync</code>要快，因为GPU和CPU之前的通信，但是会占用更多的GPU显存。</li>
<li><code>dist_async_device</code>: 该模式和<code>dist_sync_device</code>类似，但是是已异步的方式进行的。</li>
</ul>
<h4 id="开启分布式训练"><a href="#开启分布式训练" class="headerlink" title="开启分布式训练"></a>开启分布式训练</h4><p>MXNet为了用户方便的进行分布式训练提供了一个<a href="https://github.com/apache/incubator-mxnet/blob/master/tools/launch.py">tools/launch.py</a>脚本。<br>并且支持对多种类型的集群资源进行管理,,如: <code>ssh</code>,<code>mpirun</code>,<code>yarn</code>,<code>sge</code>。</p>
<p>首先clone MXNet的代码到本地:</p>
<figure class="highlight crmsh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="keyword">clone</span> <span class="title">--recursive</span> https://github.com/apache/incubator-mxnet</span><br></pre></td></tr></table></figure>
<p>我们使用代码<a href="https://github.com/apache/incubator-mxnet/blob/master/example/gluon/image_classification.py">example/gluon/image_classification.py</a>和<code>CIFAR10</code>数据集来对<code>VGG11</code>模型进行分布式训练。</p>
<figure class="highlight jboss-cli"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">cd</span> example/gluon/</span><br><span class="line"><span class="string">../../tools/launch.py</span> -n 3 -H hosts <span class="params">--launcher</span> ssh python image_classification.py <span class="params">--dataset</span> cifar10 <span class="params">--model</span> vgg11 <span class="params">--epochs</span> 1 <span class="params">--kvstore</span> dist_sync</span><br></pre></td></tr></table></figure>
<p>上面命令的具体options的解释请查看官方文档:<a href="https://mxnet.incubator.apache.org/faq/distributed_training.html#how-to-start-distributed-training" target="_blank" rel="noopener">how-to-start-distributed-training</a></p>
<p>虽然MXNet实现了多机多卡的分布式训练，但是在<code>资源隔离</code>，<code>资源调度</code>，<code>资源限制</code>以及大规模训练时<code>数据共享</code>都是不能满足需求的，所以接下来介绍下<code>MXNet</code>基于<code>Kubeflow</code>的大规模分布式训练。</p>
<h2 id="MXNet结合kubeflow进行分布式训练"><a href="#MXNet结合kubeflow进行分布式训练" class="headerlink" title="MXNet结合kubeflow进行分布式训练"></a>MXNet结合kubeflow进行分布式训练</h2><h4 id="准备工作"><a href="#准备工作" class="headerlink" title="准备工作"></a>准备工作</h4><p>在将MXNet结合kubeflow进行分布式训练之前，首先需要<a href="https://xigang.github.io/2018/12/08/kubeflow-intro/" target="_blank" rel="noopener">安装kubeflow环境</a>之前已经介绍了，这里就不在详细说明了。</p>
<p>当kubeflow基础环境部署完成之后，需要针对MXNet安装<a href="https://github.com/kubeflow/mxnet-operator">mxnet-operator</a>。具体安装<code>mxnet-operator</code>的流程如下:</p>
<ul>
<li><p>安装mxnet-operator</p>
  <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="builtin-name">export</span> <span class="attribute">KSONNET_APP</span>=/home/wangxigang/kubeflow/kubeflow_ks_app</span><br><span class="line">cd <span class="variable">$&#123;KSONNET_APP&#125;</span></span><br><span class="line">ks pkg install kubeflow/mxnet-job</span><br><span class="line">ks generate mxnet-operator mxnet-operator</span><br><span class="line">ks apply <span class="variable">$&#123;ENVIRONMENT&#125;</span> -c mxnet-operator</span><br></pre></td></tr></table></figure>
</li>
<li><p>校验MXNet是否安装成功</p>
  <figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">kubectl <span class="builtin-name">get</span> crd</span><br></pre></td></tr></table></figure>
<p>  输出如下内容代表mxnet-operator安装成功:</p>
  <figure class="highlight stylus"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">NAME                                           AGE</span><br><span class="line">...</span><br><span class="line">mxjobs<span class="selector-class">.kubeflow</span><span class="selector-class">.org</span>                       <span class="number">4</span>d</span><br><span class="line">...</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h4 id="基于kubeflow测试MXNet分布式训练"><a href="#基于kubeflow测试MXNet分布式训练" class="headerlink" title="基于kubeflow测试MXNet分布式训练"></a>基于kubeflow测试MXNet分布式训练</h4><ul>
<li><p>准备测试的训练镜像</p>
<p>示例代码: <a href="https://github.com/deepinsight/insightface">https://github.com/deepinsight/insightface</a></p>
<p>Dockerfile文件内容:</p>
<figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> mxnet/python:latest_gpu_mkl_py3</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir -p /home/insightface</span></span><br><span class="line"><span class="bash">WORKDIR /home/insightface</span></span><br><span class="line"><span class="bash">ADD insightface .</span></span><br><span class="line"><span class="bash">RUN <span class="built_in">cd</span> /home/insightface/src</span></span><br><span class="line"><span class="bash">ENTRYPOINT [<span class="string">"python3"</span>, <span class="string">"-u"</span>, <span class="string">"/home/insightface/src/train_softmax.py"</span>]</span></span><br></pre></td></tr></table></figure>
</li>
</ul>
<ul>
<li><p>创建分布式网络文件系统数据卷(cephfs)</p>
<pre><code><figure class="highlight dts"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="symbol">apiVersion:</span> v1</span><br><span class="line"><span class="symbol">kind:</span> PersistentVolumeClaim</span><br><span class="line"><span class="symbol">metadata:</span></span><br><span class="line"><span class="symbol">  name:</span> insightface-dataset</span><br><span class="line"><span class="symbol">  namespace:</span> demo</span><br><span class="line"><span class="symbol">spec:</span></span><br><span class="line"><span class="symbol">  accessModes:</span></span><br><span class="line">  - ReadWriteMany</span><br><span class="line"><span class="symbol">  resources:</span></span><br><span class="line"><span class="symbol">    requests:</span></span><br><span class="line"><span class="symbol">      storage:</span> <span class="number">50</span>Gi</span><br><span class="line"><span class="symbol">  volumeMode:</span> Filesystem</span><br></pre></td></tr></table></figure>
</code></pre></li>
</ul>
<p>   由于我们是基于kubernetes的pv和pvc的方式使用数据卷，所有集群中需要事先安装好<a href="https://github.com/kubernetes-incubator/external-storage/tree/master/ceph/cephfs">storage-class install</a>，这样当用户创建pvc时，会通过<code>storage-class</code>自动的创建pv。</p>
<p>   当创建好pv之后，用户可以将该数据卷mount到自己的开发机上，并将需要训练的数据集移到该数据卷。用于之后创建训练worker pod的时候，挂载到worker容器中，供训练模型使用。</p>
<ul>
<li><p>创建mxnet分布式训练任务</p>
  <figure class="highlight less"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="attribute">apiVersion</span>: <span class="string">"kubeflow.org/v1alpha1"</span></span><br><span class="line"><span class="attribute">kind</span>: <span class="string">"MXJob"</span></span><br><span class="line"><span class="attribute">metadata</span>:</span><br><span class="line">  <span class="attribute">name</span>: <span class="string">"insightface-train"</span></span><br><span class="line">  <span class="attribute">namespace</span>: demo</span><br><span class="line"><span class="attribute">spec</span>:</span><br><span class="line">  <span class="attribute">jobMode</span>: <span class="string">"dist"</span></span><br><span class="line">  <span class="attribute">replicaSpecs</span>:</span><br><span class="line">    - <span class="attribute">replicas</span>: <span class="number">1</span></span><br><span class="line">      <span class="attribute">mxReplicaType</span>: SCHEDULER</span><br><span class="line">      <span class="attribute">PsRootPort</span>: <span class="number">9000</span></span><br><span class="line">      <span class="attribute">template</span>:</span><br><span class="line">        <span class="attribute">spec</span>:</span><br><span class="line">          <span class="attribute">containers</span>:</span><br><span class="line">            - <span class="attribute">image</span>: xigang/<span class="attribute">mxnet-insightface</span>:gpu</span><br><span class="line">              <span class="attribute">name</span>: mxnet</span><br><span class="line">              <span class="attribute">args</span>: [<span class="string">"--data-dir"</span>, <span class="string">"/home/data/glintv2_ms1m/glintv2_ms1m/glintv2_ms1m"</span>]</span><br><span class="line">          <span class="attribute">restartPolicy</span>: OnFailure</span><br><span class="line">    - <span class="attribute">replicas</span>: <span class="number">1</span></span><br><span class="line">      <span class="attribute">mxReplicaType</span>: SERVER</span><br><span class="line">      <span class="attribute">template</span>:</span><br><span class="line">        <span class="attribute">spec</span>:</span><br><span class="line">          <span class="attribute">containers</span>:</span><br><span class="line">            - <span class="attribute">image</span>: xigang/<span class="attribute">mxnet-insightface</span>:gpu</span><br><span class="line">              <span class="attribute">name</span>: mxnet</span><br><span class="line">              <span class="attribute">args</span>: [<span class="string">"-u"</span>, <span class="string">"/home/data/glintv2_ms1m/glintv2_ms1m/glintv2_ms1m"</span>]</span><br><span class="line">          <span class="attribute">restartPolicy</span>: OnFailure</span><br><span class="line">    - <span class="attribute">replicas</span>: <span class="number">2</span></span><br><span class="line">      <span class="attribute">mxReplicaType</span>: WORKER</span><br><span class="line">      <span class="attribute">template</span>:</span><br><span class="line">        <span class="attribute">spec</span>:</span><br><span class="line">          <span class="attribute">containers</span>:</span><br><span class="line">            - <span class="attribute">image</span>: xigang/<span class="attribute">mxnet-insightface</span>:gpu</span><br><span class="line">              <span class="attribute">name</span>: mxnet</span><br><span class="line">              <span class="attribute">args</span>: [<span class="string">"--network"</span>, <span class="string">"m1"</span>, <span class="string">"--loss-type"</span>, <span class="string">"4"</span>, <span class="string">"--margin-m"</span>, <span class="string">"0.5"</span>, <span class="string">"--data-dir"</span>, <span class="string">"/home/data/glintv2_ms1m/glintv2_ms1m/glintv2_ms1m"</span>,  <span class="string">"--prefix"</span>, <span class="string">"../model-r50"</span>, <span class="string">"--kv-store"</span>, <span class="string">"dist-device-sync"</span>, <span class="string">"--gpus"</span>,<span class="string">"0,1,2,3"</span>, <span class="string">"--per-batch-size"</span>, <span class="string">"64"</span>]</span><br><span class="line">              <span class="attribute">volumeMounts</span>:</span><br><span class="line">              - <span class="attribute">mountPath</span>: <span class="string">"/home/data/glintv2_ms1m"</span></span><br><span class="line">                <span class="attribute">name</span>: cephfs-volume</span><br><span class="line">                <span class="attribute">readyOnly</span>: false</span><br><span class="line">              <span class="attribute">resources</span>:</span><br><span class="line">                <span class="attribute">limits</span>:</span><br><span class="line">                  nvidia.com/<span class="attribute">gpu</span>: <span class="number">4</span></span><br><span class="line">                  <span class="attribute">cpu</span>: <span class="number">20</span></span><br><span class="line">          <span class="attribute">volumes</span>:</span><br><span class="line">          - <span class="attribute">name</span>: cephfs-volume</span><br><span class="line">            <span class="attribute">persistentVolumeClaim</span>:</span><br><span class="line">              <span class="attribute">claimName</span>: insightface-dataset</span><br><span class="line">          <span class="attribute">restartPolicy</span>: OnFailure</span><br></pre></td></tr></table></figure>
</li>
<li><p>创建训练任务</p>
</li>
</ul>
<figure class="highlight css"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="selector-tag">kubectl</span> <span class="selector-tag">create</span> <span class="selector-tag">-f</span> <span class="selector-tag">insightface-train</span><span class="selector-class">.yaml</span></span><br></pre></td></tr></table></figure>
<ul>
<li>查看任务运行情况</li>
</ul>
<figure class="highlight maxima"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># kubectl <span class="built_in">get</span> mxjobs -n <span class="built_in">demo</span></span><br><span class="line">NAME                AGE</span><br><span class="line">insightface-train   7s</span><br></pre></td></tr></table></figure>
<figure class="highlight lsl"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">kubectl get pods -n demo</span><br><span class="line">NAME                                       READY   STATUS    RESTARTS   AGE</span><br><span class="line">insightface-train-scheduler-lhob<span class="number">-0</span>-bibup   <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">25</span>s</span><br><span class="line">insightface-train-server-lhob<span class="number">-0</span>-it68i      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">25</span>s</span><br><span class="line">insightface-train-worker-lhob<span class="number">-0</span>-zt54x      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">25</span>s</span><br><span class="line">insightface-train-worker-lhob<span class="number">-1</span>-x4y3a      <span class="number">1</span>/<span class="number">1</span>     Running   <span class="number">0</span>          <span class="number">25</span>s</span><br></pre></td></tr></table></figure>
<ul>
<li>查看训练日志的信息</li>
</ul>
<p>登录到具体的node计算节点通过<code>docker logs</code>命令查看训练的日志;</p>
<figure class="highlight routeros"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># docker logs -f fc3d73161b27</span></span><br><span class="line">num_layers 1</span><br><span class="line">image_size [112, 112]</span><br><span class="line">num_classes 142896</span><br><span class="line">Called with argument: Namespace(<span class="attribute">batch_size</span>=256, <span class="attribute">beta</span>=1000.0, <span class="attribute">beta_freeze</span>=0, <span class="attribute">beta_min</span>=5.0, <span class="attribute">bn_mom</span>=0.9, <span class="attribute">ce_loss</span>=<span class="literal">False</span>, <span class="attribute">ckpt</span>=1, <span class="attribute">color</span>=0, <span class="attribute">ctx_num</span>=4, <span class="attribute">cutoff</span>=0, <span class="attribute">data_dir</span>=<span class="string">'/home/data/glintv2_ms1m/glintv2_ms1m/glintv2_ms1m'</span>, <span class="attribute">easy_margin</span>=0, <span class="attribute">emb_size</span>=512, <span class="attribute">end_epoch</span>=1, <span class="attribute">fc7_lr_mult</span>=1.0, <span class="attribute">fc7_no_bias</span>=<span class="literal">False</span>, <span class="attribute">fc7_wd_mult</span>=1.0, <span class="attribute">gamma</span>=0.12, <span class="attribute">gpus</span>=<span class="string">'0,1,2,3'</span>, <span class="attribute">image_channel</span>=3, <span class="attribute">image_h</span>=112, <span class="attribute">image_size</span>=<span class="string">'112,112'</span>, <span class="attribute">image_w</span>=112, <span class="attribute">images_filter</span>=0, <span class="attribute">kv_store</span>=<span class="string">'dist-device-sync'</span>, <span class="attribute">loss_type</span>=4, <span class="attribute">lr</span>=0.1, <span class="attribute">lr_steps</span>=<span class="string">''</span>, <span class="attribute">margin</span>=4, <span class="attribute">margin_a</span>=1.0, <span class="attribute">margin_b</span>=0.0, <span class="attribute">margin_m</span>=0.5, <span class="attribute">margin_s</span>=64.0, <span class="attribute">max_steps</span>=0, <span class="attribute">mom</span>=0.9, <span class="attribute">network</span>=<span class="string">'m1'</span>, <span class="attribute">num_classes</span>=142896, <span class="attribute">num_layers</span>=1, <span class="attribute">per_batch_size</span>=64, <span class="attribute">power</span>=1.0, <span class="attribute">prefix</span>=<span class="string">'../model-r50'</span>, <span class="attribute">pretrained</span>=<span class="string">''</span>, <span class="attribute">rand_mirror</span>=1, <span class="attribute">rescale_threshold</span>=0, <span class="attribute">scale</span>=0.9993, <span class="attribute">target</span>=<span class="string">'lfw,cfp_fp,agedb_30'</span>, <span class="attribute">use_deformable</span>=0, <span class="attribute">verbose</span>=2000, <span class="attribute">version_act</span>=<span class="string">'prelu'</span>, <span class="attribute">version_input</span>=1, <span class="attribute">version_multiplier</span>=1.0, <span class="attribute">version_output</span>=<span class="string">'E'</span>, <span class="attribute">version_se</span>=0, <span class="attribute">version_unit</span>=3, <span class="attribute">wd</span>=0.0005)</span><br><span class="line">init mobilenet 1</span><br><span class="line">1 E 1.0 32</span><br><span class="line">INFO:root:loading recordio /home/data/glintv2_ms1m/glintv2_ms1m/glintv2_ms1m/train.rec<span class="built_in">..</span>.</span><br><span class="line">header0 label [6535379. 6678275.]</span><br><span class="line">id2range 142896</span><br><span class="line">6535378</span><br><span class="line">rand_mirror 1</span><br><span class="line">loading bin 0</span><br><span class="line">loading bin 1000</span><br><span class="line">loading bin 2000</span><br><span class="line">loading bin 3000</span><br><span class="line">loading bin 4000</span><br><span class="line">loading bin 5000</span><br><span class="line">loading bin 6000</span><br><span class="line">loading bin 7000</span><br><span class="line">loading bin 8000</span><br><span class="line">loading bin 9000</span><br><span class="line">loading bin 10000</span><br><span class="line">loading bin 11000</span><br><span class="line">(12000, 3, 112, 112)</span><br><span class="line">ver lfw</span><br><span class="line">loading bin 0</span><br><span class="line">loading bin 1000</span><br><span class="line">loading bin 2000</span><br><span class="line">loading bin 3000</span><br><span class="line">loading bin 4000</span><br><span class="line">loading bin 5000</span><br><span class="line">loading bin 6000</span><br><span class="line">loading bin 7000</span><br><span class="line">loading bin 8000</span><br><span class="line">loading bin 9000</span><br><span class="line">loading bin 10000</span><br></pre></td></tr></table></figure>
<p>这样就可以通过kubernetes对GPU服务器进行统一的资源管理，并通过kubeflow实现对各种深度学习框架的整合，来实现大规模的分布式训练任务。</p>
<h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>虽然已经完成了mxnet结合kubeflow实现大规模的分布式训练，但是除了功能上的基本跑通，还存在很多因素影响分布式训练的性能，如: GPU服务器的<code>网络带宽</code>，普通的我们使用的以太网因为通信延迟的原因，会大大影响多机扩展性。InfiniBand（IB）网络和RoCE网络因为支持RDMA,大大降低了通信延迟，相比之下，20G的以太网格延迟会大大提升。当然，对于现有的普通以太网络，也可以通过别的方法优化通信带宽的减少，比方说梯度压缩。通过梯度压缩，减少通信带宽消耗的同时，保证收敛速度和精度不会有明显下降。MXNet官方提供了梯度压缩算法，按照官方数据，最佳的时候可以达到两倍的训练速度提升，同时收敛速度和精度的下降不会超过百分之一。还有如果使用分布式网络文件系统进行数据集的存储，如果解决<code>吞吐量</code>和<code>网络延迟</code>的问题。以及本地磁盘是否是SSD，还是在训练时是否需要对大文件的数据集进行<code>record.io</code>文件格式的处理及训练前数据集的切分等等问题，都需要更进一步的处理。</p>
<h2 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h2><ul>
<li><a href="https://mxnet.incubator.apache.org/faq/distributed_training.html#how-to-start-distributed-training" target="_blank" rel="noopener">https://mxnet.incubator.apache.org/faq/distributed_training.html#how-to-start-distributed-training</a></li>
<li><a href="https://mxnet.apache.org/tutorials/vision/large_scale_classification.html" target="_blank" rel="noopener">https://mxnet.apache.org/tutorials/vision/large_scale_classification.html</a></li>
<li><a href="https://www.kubeflow.org/docs/guides/components/mxnet/" target="_blank" rel="noopener">https://www.kubeflow.org/docs/guides/components/mxnet/</a></li>
<li><a href="https://github.com/apache/incubator-mxnet">https://github.com/apache/incubator-mxnet</a></li>
<li><a href="https://github.com/apache/incubator-mxnet/issues/797">https://github.com/apache/incubator-mxnet/issues/797</a></li>
<li><a href="https://transwarpio.github.io/teaching_ml/2016/07/05/mxnet/" target="_blank" rel="noopener">https://transwarpio.github.io/teaching_ml/2016/07/05/mxnet/</a><a href=""></a></li>
</ul>
</div><div class="tags"><a href="/tags/kubernetes/">kubernetes</a><a href="/tags/kubeflow/">kubeflow</a><a href="/tags/mxnet/">mxnet</a></div><div class="post-nav"><a class="pre" href="/2019/01/30/tensorflow/">Tensorflow结合kubeflow进行分布式训练</a><a class="next" href="/2018/12/31/Orphaned-pod/">定位 Orphaned Pod Found - but Volume Paths Are Still Present on Disk 问题</a></div><div id="container"></div><link rel="stylesheet" type="text/css" href="//unpkg.com/gitalk/dist/gitalk.css?v=0.0.0"><script type="text/javascript" src="//cdn.bootcss.com/blueimp-md5/2.10.0/js/md5.js?v=0.0.0"></script><script type="text/javascript" src="//unpkg.com/gitalk/dist/gitalk.min.js?v=0.0.0"></script><script>var gitalk = new Gitalk({
  clientID: '86d1945e3a9358946043',
  clientSecret: '304f48ee3394ae5dab75d19a966506e170d850f6',
  repo: 'xigang.github.io',
  owner: 'xigang',
  admin: ['xigang'],
  id: md5(location.pathname),
  distractionFreeMode: false
})
gitalk.render('container')
</script></div></div></div><div class="pure-u-1-4 hidden_mid_and_down"><div id="sidebar"><div class="widget"><form class="search-form" action="//www.baidu.com/baidu" method="get" accept-charset="utf-8" target="_blank"><input type="search" name="word" maxlength="20" placeholder="Search"/><input type="hidden" name="si" value="https://github.com/xigang"/><input name="tn" type="hidden" value="bds"/><input name="cl" type="hidden" value="3"/><input name="ct" type="hidden" value="2097152"/><input name="s" type="hidden" value="on"/></form></div><div class="widget"><div class="widget-title"><i class="fa fa-folder-o"> 分类</i></div><ul class="category-list"><li class="category-list-item"><a class="category-list-link" href="/categories/Linux/">Linux</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/docker/">docker</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/etcd/">etcd</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/kubernetes/">kubernetes</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/microservices/">microservices</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/日志监控/">日志监控</a></li><li class="category-list-item"><a class="category-list-link" href="/categories/机器学习/">机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-star-o"> 标签</i></div><div class="tagcloud"><a href="/tags/kernel/" style="font-size: 15px;">kernel</a> <a href="/tags/kubernetes/" style="font-size: 15px;">kubernetes</a> <a href="/tags/prometheus/" style="font-size: 15px;">prometheus</a> <a href="/tags/kapacitor/" style="font-size: 15px;">kapacitor</a> <a href="/tags/alertmanager/" style="font-size: 15px;">alertmanager</a> <a href="/tags/bosun/" style="font-size: 15px;">bosun</a> <a href="/tags/Linux/" style="font-size: 15px;">Linux</a> <a href="/tags/cgroup/" style="font-size: 15px;">cgroup</a> <a href="/tags/ceph/" style="font-size: 15px;">ceph</a> <a href="/tags/etcd/" style="font-size: 15px;">etcd</a> <a href="/tags/kubeflow/" style="font-size: 15px;">kubeflow</a> <a href="/tags/scheduler/" style="font-size: 15px;">scheduler</a> <a href="/tags/docker/" style="font-size: 15px;">docker</a> <a href="/tags/microservices/" style="font-size: 15px;">microservices</a> <a href="/tags/mxnet/" style="font-size: 15px;">mxnet</a> <a href="/tags/tensorflow/" style="font-size: 15px;">tensorflow</a></div></div><div class="widget"><div class="widget-title"><i class="fa fa-file-o"> 最近文章</i></div><ul class="post-list"><li class="post-list-item"><a class="post-list-link" href="/2019/06/01/cgroupv2/">CGROUPS VERSION 2</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/05/11/bosun/">Prometheus基于Bosun框架进行告警</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/04/09/container-resource-metrics/">A Deep Dive Into Kubernetes Metrics - Container Resource Metrics</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/03/15/metrics-servere/">Kubernetes Metrics-Server介绍及源码分析</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/02/17/gang-scheduler/">适合AI场景的调度器 - Gang-Schedule</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/30/tensorflow/">Tensorflow结合kubeflow进行分布式训练</a></li><li class="post-list-item"><a class="post-list-link" href="/2019/01/17/mxnet/">MXNet结合kubeflow进行分布式训练</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/31/Orphaned-pod/">定位 Orphaned Pod Found - but Volume Paths Are Still Present on Disk 问题</a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/14/prometheus/">记一次InfoQ采访 <<360容器平台监控实践>></a></li><li class="post-list-item"><a class="post-list-link" href="/2018/12/08/kubeflow-intro/">Kubeflow使用Kubernetes进行机器学习</a></li></ul></div><div class="widget"><div class="widget-title"><i class="fa fa-external-link"> 友情链接</i></div><ul></ul><a href="http://gogap.cn/" title="gogap" target="_blank">gogap</a><ul></ul><a href="http://www.0x7c00.net/" title="31744" target="_blank">31744</a><ul></ul><a href="https://www.opsdev.cn/" title="360opsdev" target="_blank">360opsdev</a></div></div></div><div class="pure-u-1 pure-u-md-3-4"><div id="footer">Copyright © 2019 <a href="/." rel="nofollow">xigang's home.</a> Powered by<a rel="nofollow" target="_blank" href="https://hexo.io"> Hexo.</a><a rel="nofollow" target="_blank" href="https://github.com/tufu9441/maupassant-hexo"> Theme</a> by<a rel="nofollow" target="_blank" href="https://github.com/pagecho"> Cho.</a></div></div></div><a class="show" id="rocket" href="#top"></a><script type="text/javascript" src="/js/totop.js?v=0.0.0" async></script><script type="text/javascript" src="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.js" async></script><script type="text/javascript" src="/js/fancybox.js?v=0.0.0" async></script><link rel="stylesheet" type="text/css" href="//cdn.bootcss.com/fancybox/3.3.5/jquery.fancybox.min.css"><script type="text/javascript" src="/js/codeblock-resizer.js?v=0.0.0"></script><script type="text/javascript" src="/js/smartresize.js?v=0.0.0"></script></div></body></html>